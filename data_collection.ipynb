{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download ablums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Loop through the years from 1960 to 2023\n",
    "for year in range(1960, 2024):\n",
    "    # URL to scrape\n",
    "    url = f\"https://digitaldreamdoor.com/pages/albums_by_year/albums_{year}.html\"\n",
    "\n",
    "    # Simulate browser headers for the HTTP request\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/89.0.4389.82 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the webpage content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # List to store album and artist data\n",
    "        albums_and_artists = []\n",
    "\n",
    "        # First structure parsing logic\n",
    "        divs = soup.find_all(\"div\", class_=\"list\")\n",
    "        for div in divs:\n",
    "            album_rows = div.text.split('\\n')  # Split rows by newline\n",
    "            for row in album_rows:\n",
    "                if \" - \" in row:  # Identify rows with album and artist data\n",
    "                    parts = row.split(\" - \", 1)  # Split into album and artist\n",
    "                    album = parts[0].split(\".\", 1)[-1].strip()  # Extract album name\n",
    "                    artist = parts[1].strip()  # Extract artist name\n",
    "                    albums_and_artists.append({\"Album Name\": album, \"Artist Name\": artist})\n",
    "\n",
    "        # If data was extracted using the first structure\n",
    "        if albums_and_artists:\n",
    "            df = pd.DataFrame(albums_and_artists)\n",
    "            df['Year'] = year\n",
    "\n",
    "        # Second structure parsing logic (fallback if the first method fails)\n",
    "        if not albums_and_artists:\n",
    "            for div in divs:\n",
    "                lines = div.stripped_strings  # Extract clean lines from the div\n",
    "                for line in lines:\n",
    "                    if \" - \" in line:  # Identify lines with album and artist data\n",
    "                        parts = line.split(\" - \", 1)  # Split into album and artist\n",
    "                        album = parts[0].split(\".\", 1)[-1].strip()  # Extract album name\n",
    "                        artist = parts[1].strip()  # Extract artist name\n",
    "                        albums_and_artists.append({\"Album Name\": album, \"Artist Name\": artist})\n",
    "            \n",
    "            # If data was extracted using the second structure\n",
    "            if albums_and_artists:\n",
    "                df = pd.DataFrame(albums_and_artists)\n",
    "                df['Year'] = year\n",
    "\n",
    "        # Create a directory to save CSV files if it does not exist\n",
    "        if not os.path.exists(\"album\"):\n",
    "            os.makedirs(\"album\")\n",
    "\n",
    "        # Save the data to a CSV file\n",
    "        df.to_csv(f\"album/top100_albums_{year}.csv\", index=False, encoding=\"utf-8\")\n",
    "    else:\n",
    "        # Print an error message if the request fails\n",
    "        print(f\"Failed request, status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the songs in each ablum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import musicbrainzngs\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize MusicBrainz API with a user agent\n",
    "musicbrainzngs.set_useragent(\"AlbumInfoFetcher\", \"1.0\", \"your_email@example.com\")\n",
    "\n",
    "# Function to fetch album songs and metadata\n",
    "def get_album_songs(album_name):\n",
    "    try:\n",
    "        # Search for the album using the MusicBrainz API\n",
    "        result = musicbrainzngs.search_releases(release=album_name, limit=1)\n",
    "        \n",
    "        # Check if any results are found\n",
    "        if not result['release-list']:\n",
    "            print(f\"No results found for album: {album_name}\")\n",
    "            return []\n",
    "\n",
    "        # Select the first matching album\n",
    "        release = result['release-list'][0]\n",
    "        release_id = release['id']\n",
    "\n",
    "        # Fetch detailed album information using the release ID\n",
    "        album_data = musicbrainzngs.get_release_by_id(release_id, includes=[\"recordings\", \"tags\"])\n",
    "        release_info = album_data['release']\n",
    "        tracks = release_info['medium-list'][0]['track-list']\n",
    "\n",
    "        # Extract general album metadata\n",
    "        album_details = {\n",
    "            \"Album Name\": album_name,\n",
    "            \"Status\": release_info.get('status', 'Unknown'),\n",
    "            \"Quality\": release_info.get('quality', 'Unknown'),\n",
    "            \"Packaging\": release_info.get('packaging', 'Unknown'),\n",
    "            \"Language\": release_info.get('text-representation', {}).get('language', 'Unknown'),\n",
    "            \"Script\": release_info.get('text-representation', {}).get('script', 'Unknown'),\n",
    "            \"Release Date\": release_info.get('date', 'Unknown'),\n",
    "            \"Release Country\": release_info.get('country', 'Unknown'),\n",
    "            \"Has Artwork\": release_info.get('cover-art-archive', {}).get('artwork', 'false'),\n",
    "            \"Front Cover Available\": release_info.get('cover-art-archive', {}).get('front', 'false'),\n",
    "            \"Back Cover Available\": release_info.get('cover-art-archive', {}).get('back', 'false'),\n",
    "        }\n",
    "\n",
    "        # Extract track-level metadata\n",
    "        songs = []\n",
    "        for track in tracks:\n",
    "            recording = track.get('recording', {})\n",
    "            \n",
    "            # Extract tags/genres for the recording\n",
    "            recording_tags = recording.get('tag-list', [])\n",
    "            recording_genres = \", \".join([tag['name'] for tag in recording_tags]) if recording_tags else \"Unknown\"\n",
    "\n",
    "            # Combine album-level and track-level metadata\n",
    "            song_details = {\n",
    "                \"Track Number\": track.get('position', 'Unknown'),\n",
    "                \"Title\": recording.get('title', 'Unknown'),\n",
    "                \"Length (ms)\": recording.get('length', 'Unknown'),\n",
    "                \"Recording Genres\": recording_genres if recording_genres else \"Unknown\",\n",
    "                **album_details,\n",
    "            }\n",
    "            songs.append(song_details)\n",
    "\n",
    "        return songs\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exceptions and print error messages\n",
    "        print(f\"Error fetching album data: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"songs\"):\n",
    "    os.makedirs(\"songs\")\n",
    "for year in range(1960,2024):\n",
    "    df = pd.read_csv(f'album/top100_albums_{year}.csv')\n",
    "    all_songs = []\n",
    "    for name in df['Album Name']:\n",
    "        songs_data = get_album_songs(name)\n",
    "        if songs_data:\n",
    "            all_songs.extend(songs_data)\n",
    "    \n",
    "    if all_songs:\n",
    "        df_all_songs = pd.DataFrame(all_songs)\n",
    "        df_all_songs.to_csv(f\"songs/top100_albums_{year}_songs.csv\", index=False)\n",
    "        print(f'finish exacting{year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the lyrics of each song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import lyricsgenius\n",
    "\n",
    "# Create directories for saving lyrics and processed songs\n",
    "if not os.path.exists(\"lyrics\"):\n",
    "    os.makedirs(\"lyrics\")\n",
    "if not os.path.exists(\"songs_net\"):\n",
    "    os.makedirs(\"songs_net\")\n",
    "\n",
    "# Function to sanitize filenames by replacing invalid characters\n",
    "def safe_filename(filename):\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius(\"FZyxPjY4GKltQjpyKulBfJZwwZWHNySpmbSOtRN1ELpB9MV5b2GSsh6i1dQEgvse\")\n",
    "\n",
    "# Process songs year by year\n",
    "for year in range(1960, 2024):  # Adjust year range as needed\n",
    "    print(f\"Processing year: {year}\")\n",
    "    try:\n",
    "        # Load song and album data\n",
    "        df_song = pd.read_csv(f'songs/top100_albums_{year}_songs.csv')\n",
    "        df_album = pd.read_csv(f'album/top100_albums_{year}.csv')\n",
    "        \n",
    "        # Merge song and album data on 'Album Name'\n",
    "        merged_left = pd.merge(df_song, df_album, on='Album Name', how='left')\n",
    "\n",
    "        # List to keep track of rows where lyrics are not found\n",
    "        index_record = []\n",
    "\n",
    "        # Process each song in the merged data\n",
    "        for index, row in merged_left.iterrows():\n",
    "            try:\n",
    "                # Search for lyrics using Genius API\n",
    "                time.sleep(1)  # Avoid hitting the API rate limit\n",
    "                song = genius.search_song(row['Title'], row['Artist Name'])\n",
    "                if song:\n",
    "                    lyrics = song.lyrics\n",
    "                else:\n",
    "                    lyrics = None\n",
    "\n",
    "                # If lyrics are not found, log and skip\n",
    "                if not lyrics:\n",
    "                    print(f\"Lyrics not found for {row['Artist Name']} - {row['Title']}\")\n",
    "                    index_record.append(index)\n",
    "                    continue\n",
    "\n",
    "                # Save lyrics to a text file\n",
    "                file_path = f'lyrics/{safe_filename(row[\"Album Name\"])}_{safe_filename(row[\"Artist Name\"])}_{safe_filename(row[\"Title\"])}.txt'\n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(lyrics)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle any errors while downloading lyrics\n",
    "                print(f\"Error downloading lyrics for {row['Artist Name']} - {row['Title']}: {e}\")\n",
    "                index_record.append(index)\n",
    "\n",
    "        # Remove rows where lyrics were not found\n",
    "        merged_left = merged_left.drop(index=index_record)\n",
    "\n",
    "        # Save the updated DataFrame\n",
    "        merged_left.to_csv(f'songs_net/top100_albums_{year}_songs.csv', index=False)\n",
    "        print(f\"Finished processing year: {year}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors while processing the year\n",
    "        print(f\"Error processing year {year}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
